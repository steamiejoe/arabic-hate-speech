{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f027ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../data/raw/\"\n",
    "\n",
    "\n",
    "mlma = pd.read_csv(base_path + \"MLMA.csv\")\n",
    "\n",
    "\n",
    "osact_train = pd.read_csv(\n",
    "    base_path + \"OSACT2022-sharedTask-train.txt\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"id\", \"tweet\", \"offensiveness\", \"hate_speech\", \"vulgarity\", \"violence\"],\n",
    "    engine=\"python\",\n",
    "    quoting=3,\n",
    "    on_bad_lines=\"skip\",\n",
    ")\n",
    "\n",
    "\n",
    "osact_dev = pd.read_csv(\n",
    "    base_path + \"OSACT2022-sharedTask-dev.txt\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"id\", \"tweet\", \"offensiveness\", \"hate_speech\", \"vulgarity\", \"violence\"],\n",
    "    engine=\"python\",\n",
    "    quoting=3,\n",
    "    on_bad_lines=\"skip\",\n",
    ")\n",
    "\n",
    "\n",
    "sohateful = pd.read_excel(base_path + \"SoHateful.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "armi = pd.read_csv(base_path + \"ArMI2021_training.tsv\", sep=\"\\t\")\n",
    "\n",
    "ar_hf = pd.read_csv(base_path + \"ar_hf_112024.csv\")\n",
    "\n",
    "\n",
    "def process_mlma(row):\n",
    "    sentiment = str(row[\"sentiment\"]).lower()\n",
    "\n",
    "    target = str(row[\"target\"]).lower()\n",
    "\n",
    "    is_hate = 1 if \"hateful\" in sentiment else 0\n",
    "\n",
    "    oh = 0\n",
    "\n",
    "    gh = 0\n",
    "\n",
    "    rh = 0\n",
    "\n",
    "    if is_hate:\n",
    "        if \"origin\" in target:\n",
    "            oh = 1\n",
    "\n",
    "        if \"religion\" in target:\n",
    "            rh = 1\n",
    "\n",
    "        if target in [\"gender\"]:\n",
    "            gh = 1\n",
    "\n",
    "    return pd.Series([row[\"tweet\"], is_hate, oh, gh, rh])\n",
    "\n",
    "\n",
    "mlma_processed = mlma.apply(process_mlma, axis=1)\n",
    "\n",
    "mlma_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "mlma_processed[\"source\"] = \"MLMA\"\n",
    "\n",
    "\n",
    "# --- 3. Process OSACT (Train + Dev) ---\n",
    "\n",
    "osact_combined = pd.concat([osact_train, osact_dev], ignore_index=True)\n",
    "\n",
    "osact_combined.columns = [\n",
    "    \"id\",\n",
    "    \"tweet\",\n",
    "    \"offensiveness\",\n",
    "    \"hate_speech\",\n",
    "    \"vulgarity\",\n",
    "    \"violence\",\n",
    "]\n",
    "\n",
    "assert osact_combined[\"tweet\"].notna().all()\n",
    "\n",
    "assert osact_combined[\"tweet\"].str.len().gt(1).all()\n",
    "\n",
    "osact_combined.sample(5)[\"tweet\"].values\n",
    "\n",
    "\n",
    "def process_osact(row):\n",
    "    hs_label = str(row[\"hate_speech\"])\n",
    "\n",
    "    is_hate = 1 if hs_label != \"NOT_HS\" else 0\n",
    "\n",
    "    oh = 0\n",
    "\n",
    "    gh = 0\n",
    "\n",
    "    rh = 0\n",
    "\n",
    "    if is_hate:\n",
    "        if hs_label == \"HS1\":\n",
    "            oh = 1\n",
    "\n",
    "        elif hs_label == \"HS6\":\n",
    "            gh = 1\n",
    "\n",
    "        elif hs_label in [\"HS2\", \"HS3\"]:\n",
    "            rh = 1\n",
    "\n",
    "    return pd.Series([row[\"tweet\"], is_hate, oh, gh, rh])\n",
    "\n",
    "\n",
    "osact_processed = osact_combined.apply(process_osact, axis=1)\n",
    "\n",
    "osact_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "osact_processed[\"source\"] = \"OSACT\"\n",
    "\n",
    "\n",
    "def process_sohateful(row):\n",
    "    q4_4 = str(\n",
    "        row[\"Q4.4 :Hate speech type خطاب كراهية موجه ضد أشخاص لهم سمات مشتركة\"]\n",
    "    ).lower()\n",
    "\n",
    "    text = row[\"info_text\"]\n",
    "\n",
    "    if q4_4 in [\"nan\", \"no\", \"none\"]:\n",
    "        is_hate = 0\n",
    "\n",
    "        oh, gh, rh = 0, 0, 0\n",
    "\n",
    "    else:\n",
    "        is_hate = 1\n",
    "\n",
    "        oh, gh, rh = 0, 0, 0\n",
    "\n",
    "        if \"origin-race-nationality\" in q4_4:\n",
    "            oh = 1\n",
    "\n",
    "        if \"gender\" in q4_4:\n",
    "            gh = 1\n",
    "\n",
    "        if \"religion-sect\" in q4_4 or \"ideology\" in q4_4:\n",
    "            rh = 1\n",
    "\n",
    "    return pd.Series([text, is_hate, oh, gh, rh])\n",
    "\n",
    "\n",
    "sohateful_processed = sohateful.apply(process_sohateful, axis=1)\n",
    "\n",
    "sohateful_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "sohateful_processed[\"source\"] = \"SoHateful\"\n",
    "\n",
    "\n",
    "exclusions = [\"discredit\", \"damning\", \"derailing\", \"threat of violence\"]\n",
    "\n",
    "armi_filtered = armi[~armi[\"category\"].isin(exclusions)].copy()\n",
    "\n",
    "\n",
    "def process_armi(row):\n",
    "    is_misogyny = 1 if row[\"misogyny\"] == \"misogyny\" else 0\n",
    "\n",
    "    return pd.Series([row[\"text\"], is_misogyny, 0, is_misogyny, 0])\n",
    "\n",
    "\n",
    "armi_processed = armi_filtered.apply(process_armi, axis=1)\n",
    "\n",
    "armi_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "armi_processed[\"source\"] = \"ArMI\"\n",
    "\n",
    "\n",
    "brothers_df = ar_hf[ar_hf[\"dataset\"] == \"brothers\"].copy()\n",
    "\n",
    "\n",
    "def process_brothers(row):\n",
    "    # labels: 1 = Hate, 0 = Not Hate\n",
    "\n",
    "    is_hate = int(row[\"labels\"])\n",
    "\n",
    "    oh = 0\n",
    "\n",
    "    gh = 0\n",
    "\n",
    "    rh = 0\n",
    "\n",
    "    if is_hate:\n",
    "        rh = 1\n",
    "\n",
    "    return pd.Series([row[\"text\"], is_hate, oh, gh, rh])\n",
    "\n",
    "\n",
    "brothers_processed = brothers_df.apply(process_brothers, axis=1)\n",
    "\n",
    "brothers_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "brothers_processed[\"source\"] = \"Brothers\"\n",
    "\n",
    "\n",
    "egy_train = pd.read_parquet(base_path + \"train-egyptian-5-way.parquet\")\n",
    "\n",
    "egy_test = pd.read_parquet(base_path + \"test-egyptian-5-way.parquet\")\n",
    "\n",
    "\n",
    "egy = pd.concat([egy_train, egy_test], ignore_index=True)\n",
    "\n",
    "egy[\"label\"] = egy[\"label\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "egy = egy[egy[\"label\"].isin([\"racism\", \"sexism\", \"religious discrimination\"])].copy()\n",
    "\n",
    "\n",
    "def process_egyptian(row):\n",
    "    label = row[\"label\"]\n",
    "\n",
    "    is_hate = 1\n",
    "\n",
    "    oh = gh = rh = 0\n",
    "\n",
    "    if label == \"racism\":\n",
    "        oh = 1\n",
    "\n",
    "    elif label == \"sexism\":\n",
    "        gh = 1\n",
    "\n",
    "    elif label == \"religious discrimination\":\n",
    "        rh = 1\n",
    "\n",
    "    return pd.Series([row[\"text\"], is_hate, oh, gh, rh])\n",
    "\n",
    "\n",
    "egy_processed = egy.apply(process_egyptian, axis=1)\n",
    "\n",
    "egy_processed.columns = [\"text\", \"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "egy_processed[\"source\"] = \"Egyptian5Way\"\n",
    "\n",
    "\n",
    "harmonized_df = pd.concat(\n",
    "    [\n",
    "        mlma_processed,\n",
    "        osact_processed,\n",
    "        sohateful_processed,\n",
    "        armi_processed,\n",
    "        brothers_processed,\n",
    "        egy_processed,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "\n",
    "cols = [\"is_hate\", \"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "harmonized_df[cols] = harmonized_df[cols].astype(int)\n",
    "\n",
    "\n",
    "print(\"Total rows:\", len(harmonized_df))\n",
    "\n",
    "print(\"Distribution:\\n\", harmonized_df[cols].sum())\n",
    "\n",
    "\n",
    "harmonized_df.to_csv('../data/interim/Unified_Datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bed41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBS = [\"OH\", \"GH\", \"RH\"]\n",
    "\n",
    "PRIORITY = [\"OSACT\", \"Egyptian5Way\", \"ArMI\", \"Brothers\", \"MLMA\", \"SoHateful\"]\n",
    "\n",
    "\n",
    "def resolve_group(group):\n",
    "    sources = list(group[\"source\"].unique())\n",
    "\n",
    "    # If any source says it's hate, we generally trust it\n",
    "\n",
    "    is_hate = int(group[\"is_hate\"].max() == 1)\n",
    "\n",
    "    oh = gh = rh = 0\n",
    "\n",
    "    # Determine highest-priority dataset present for this specific tweet\n",
    "\n",
    "    chosen = None\n",
    "\n",
    "    for p in PRIORITY:\n",
    "        if p in sources:\n",
    "            chosen = p\n",
    "\n",
    "            break\n",
    "\n",
    "    if chosen == \"OSACT\":\n",
    "        row = group[group[\"source\"] == \"OSACT\"].iloc[0]\n",
    "\n",
    "        oh, gh, rh = row[SUBS]\n",
    "\n",
    "    elif chosen == \"Egyptian5Way\":\n",
    "        row = group[group[\"source\"] == \"Egyptian5Way\"].iloc[0]\n",
    "\n",
    "        oh, gh, rh = row[SUBS]\n",
    "\n",
    "    elif chosen == \"SoHateful\":\n",
    "        sh = group[group[\"source\"] == \"SoHateful\"][SUBS].sum()\n",
    "\n",
    "        oh, gh, rh = (sh > 0).astype(int)\n",
    "\n",
    "    elif chosen == \"ArMI\":\n",
    "        # ArMI is purely Gender Hate\n",
    "\n",
    "        gh = int(group[group[\"source\"] == \"ArMI\"][\"is_hate\"].max() == 1)\n",
    "\n",
    "    elif chosen == \"Brothers\":\n",
    "        # Brothers is purely Religious Hate\n",
    "\n",
    "        rh = int(group[group[\"source\"] == \"Brothers\"][\"is_hate\"].max() == 1)\n",
    "\n",
    "    elif chosen == \"MLMA\":\n",
    "        ml = group[group[\"source\"] == \"MLMA\"][SUBS].sum()\n",
    "\n",
    "        oh, gh, rh = (ml > 0).astype(int)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"text\": group[\"text\"].iloc[0],\n",
    "            \"is_hate\": is_hate,\n",
    "            \"OH\": int(oh),\n",
    "            \"GH\": int(gh),\n",
    "            \"RH\": int(rh),\n",
    "            \"sources\": \",\".join(sorted(sources)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Resolving duplicates... (This may take a moment)\")\n",
    "\n",
    "clean_df = harmonized_df.groupby(\"text\", as_index=False).apply(resolve_group)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"Final rows:\", len(clean_df))\n",
    "\n",
    "print(\"Final distribution:\")\n",
    "\n",
    "print(clean_df[SUBS + [\"is_hate\"]].sum())\n",
    "\n",
    "clean_df.to_csv('../data/processed/Harmonized_Dataset.csv', index=False)\n",
    "\n",
    "print(\"Saved: Harmonized_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b818c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original shape: {clean_df.shape}\")\n",
    "\n",
    "\n",
    "undefined_mask = (\n",
    "    (clean_df[\"is_hate\"] == 1)\n",
    "    & (clean_df[\"OH\"] == 0)\n",
    "    & (clean_df[\"GH\"] == 0)\n",
    "    & (clean_df[\"RH\"] == 0)\n",
    ")\n",
    "\n",
    "\n",
    "# Filter the dataframe\n",
    "\n",
    "clean_df = clean_df[~undefined_mask].copy()\n",
    "\n",
    "\n",
    "# Reset index\n",
    "\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"New shape: {clean_df.shape}\")\n",
    "\n",
    "print(f\"Dropped {undefined_mask.sum()} rows.\")\n",
    "\n",
    "remaining = (\n",
    "    (clean_df[\"is_hate\"] == 1)\n",
    "    & (clean_df[\"OH\"] == 0)\n",
    "    & (clean_df[\"GH\"] == 0)\n",
    "    & (clean_df[\"RH\"] == 0)\n",
    ").sum()\n",
    "\n",
    "print(f\"Remaining undefined samples: {remaining}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
